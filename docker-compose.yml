# =============================================================================
# OpenTelemetry Observability Stack
# =============================================================================
# A production-ready observability infrastructure with reliability features:
#   - Persistent queues (no data loss on restart)
#   - Resource limits (prevents OOM)
#   - Health checks with auto-restart
#   - Graceful shutdown
#   - Proper startup ordering
#
# Quick Start:
#   make up              # Start the stack
#   make down            # Stop the stack
#   make status          # Check health
#   make help            # Show all commands
#
# Access UIs:
#   Grafana:    http://localhost:3000 (admin/admin)
#   Jaeger:     http://localhost:16686
#   Prometheus: http://localhost:9090
#
# Send telemetry to:
#   OTLP gRPC: localhost:4317
#   OTLP HTTP: localhost:4318
# =============================================================================

services:
  # ===========================================
  # Jaeger - Distributed Tracing
  # ===========================================
  jaeger:
    image: jaegertracing/all-in-one:1.51
    container_name: otel-jaeger
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686"    # Jaeger UI
      - "6831:6831/udp"                      # Jaeger agent (Thrift compact)
      - "6832:6832/udp"                      # Jaeger agent (Thrift binary)
      - "14268:14268"                        # Jaeger collector HTTP
      - "14250:14250"                        # Jaeger collector gRPC
      - "9411:9411"                          # Zipkin compatible endpoint
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - COLLECTOR_OTLP_ENABLED=true
      # Use Badger for persistent storage with configurable retention
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
      - BADGER_SPAN_STORE_TTL=${TRACES_RETENTION:-720h}
    volumes:
      - jaeger-data:/badger
    networks:
      - observability
    restart: unless-stopped
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  # ===========================================
  # Prometheus - Metrics Collection
  # ===========================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: otel-prometheus
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts:/etc/prometheus/alerts:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=${METRICS_RETENTION:-30d}'
      - '--storage.tsdb.wal-compression'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - observability
    restart: unless-stopped
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  # ===========================================
  # Loki - Log Aggregation
  # ===========================================
  loki:
    image: grafana/loki:2.9.0
    container_name: otel-loki
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    ports:
      - "${LOKI_PORT:-3100}:3100"
    environment:
      - LOGS_RETENTION=${LOGS_RETENTION:-720h}
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/loki-config.yaml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/loki-config.yaml -config.expand-env=true
    networks:
      - observability
    restart: unless-stopped
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ===========================================
  # OpenTelemetry Collector - Unified Pipeline
  # ===========================================
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.91.0
    container_name: otel-collector
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
      - otel-collector-data:/var/lib/otelcol
    ports:
      - "${OTEL_GRPC_PORT:-4317}:4317"   # OTLP gRPC receiver
      - "${OTEL_HTTP_PORT:-4318}:4318"   # OTLP HTTP receiver
      - "8888:8888"                       # Prometheus metrics (self)
      - "8889:8889"                       # Prometheus exporter
      - "13133:13133"                     # Health check
      - "1888:1888"                       # pprof (profiling)
      - "55679:55679"                     # ZPages (debug)
    networks:
      - observability
    depends_on:
      jaeger:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
    restart: unless-stopped
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:13133/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ===========================================
  # Grafana - Dashboards & Visualization
  # ===========================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: otel-grafana
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-clock-panel
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3000}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - observability
    depends_on:
      prometheus:
        condition: service_healthy
      jaeger:
        condition: service_healthy
      loki:
        condition: service_healthy
    restart: unless-stopped
    stop_grace_period: 15s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ===========================================
  # Node Exporter - Host Metrics
  # NOTE: On macOS, this provides container VM metrics, not host metrics.
  #       For true host metrics on macOS, run node_exporter natively.
  # ===========================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: otel-node-exporter
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--no-collector.systemd'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    networks:
      - observability
    restart: unless-stopped
    stop_grace_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ===========================================
  # Seq - Structured Logging (Optional)
  # Great for .NET applications with Serilog
  # ===========================================
  seq:
    image: datalust/seq:latest
    container_name: otel-seq
    logging:
      driver: "json-file"
      options:
        max-size: "30m"
        max-file: "3"
    profiles:
      - seq
      - full
    ports:
      - "${SEQ_API_PORT:-5341}:5341"    # Ingestion API
      - "${SEQ_UI_PORT:-5380}:80"        # UI
    environment:
      - ACCEPT_EULA=Y
      - SEQ_FIRSTRUN_ADMINPASSWORDHASH=${SEQ_ADMIN_PASSWORD_HASH:-}
    volumes:
      - seq-data:/data
    networks:
      - observability
    restart: unless-stopped
    stop_grace_period: 15s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:80/api"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

networks:
  observability:
    driver: bridge
    name: observability

volumes:
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  seq-data:
    driver: local
  loki-data:
    driver: local
  jaeger-data:
    driver: local
  otel-collector-data:
    driver: local
