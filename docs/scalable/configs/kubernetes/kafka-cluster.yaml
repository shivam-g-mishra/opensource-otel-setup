# Kubernetes - Kafka Cluster using Strimzi
#
# Prerequisites:
# 1. Install Strimzi operator:
#    kubectl create namespace kafka
#    kubectl apply -f 'https://strimzi.io/install/latest?namespace=kafka'
#
# Apply: kubectl apply -f kafka-cluster.yaml

---
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: otel-kafka
  namespace: kafka
spec:
  kafka:
    version: 3.6.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    config:
      # Replication settings
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      
      # Retention settings
      log.retention.hours: 24
      log.retention.bytes: 10737418240  # 10GB per partition
      
      # Performance tuning
      num.network.threads: 8
      num.io.threads: 16
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        deleteClaim: false
        class: standard  # Change to your storage class
    resources:
      requests:
        memory: 4Gi
        cpu: "1"
      limits:
        memory: 8Gi
        cpu: "2"
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml
  
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 20Gi
      deleteClaim: false
      class: standard
    resources:
      requests:
        memory: 1Gi
        cpu: "500m"
      limits:
        memory: 2Gi
        cpu: "1"
  
  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 256Mi
          cpu: "100m"
        limits:
          memory: 512Mi
          cpu: "500m"
    userOperator:
      resources:
        requests:
          memory: 256Mi
          cpu: "100m"
        limits:
          memory: 512Mi
          cpu: "500m"

---
# Kafka Topics for telemetry
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: otlp-traces
  namespace: kafka
  labels:
    strimzi.io/cluster: otel-kafka
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 86400000  # 24 hours
    segment.bytes: 1073741824  # 1GB
    cleanup.policy: delete

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: otlp-metrics
  namespace: kafka
  labels:
    strimzi.io/cluster: otel-kafka
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 86400000
    segment.bytes: 1073741824
    cleanup.policy: delete

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: otlp-logs
  namespace: kafka
  labels:
    strimzi.io/cluster: otel-kafka
spec:
  partitions: 12
  replicas: 3
  config:
    retention.ms: 86400000
    segment.bytes: 1073741824
    cleanup.policy: delete

---
# Metrics configuration for Prometheus scraping
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics
  namespace: kafka
data:
  kafka-metrics-config.yml: |
    lowercaseOutputName: true
    rules:
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
        clientId: "$3"
        topic: "$4"
        partition: "$5"
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
        clientId: "$3"
        broker: "$4:$5"
    - pattern: kafka.server<type=(.+), name=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
